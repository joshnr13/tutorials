{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcPy on Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, when you installed anaconda, you grabbed the 64-bit version. How do I know this? we did this together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to check what bit count your installation of python is uses the sys module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linux2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "('32bit', 'WindowsPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yours will probably not tell you that you're on Linux, and if it does, you're probably doing something weird :)\n",
    "\n",
    "Grab the 32-bit version of Anaconda python from the [continuum.io website](http://continuum.io/downloads). You could also grab Enthought's canopy, but I prefer Anaconda due to the `conda` package manager. \n",
    "\n",
    "Go ahead and install it, but make sure you UNCLICK the second option, \"Register Anaconda as the Default Python.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you must navigate to where your ArcGIS python is installed. For me, this is `C:\\Python27\\ArcGIS10.2\\Lib\\site-packages`\n",
    "\n",
    "Then, you must copy the `desktop10.2.pth` file and add it to the Anaconda/Enthought `site-packages` folder. For me, this is in `C:\\Users\\ljw\\Anaconda\\Lib\\site-packages` \n",
    "\n",
    "Once you place the path there, try opening an ipython terminal or ipython notebook. You should be able to `import arcpy` from there. It'll take a bit to compile and import, but once done, you should have access to arcpy as any other python package!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Notebook Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yesterday, we talked about providing you a few examples of other notebooks. I've assembled a few from the internet, and I'll show you a few of my own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a very famous early adopter of this format was the book [Bayesian Stats for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers). I'll boot a notebook from here now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other books, like [Signal Processing in Python](https://github.com/unpingco/Python-for-Signal-Processing), for any aspiring audio engineers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, collections of teaching notebooks make good starts for people who want to know more about python for GIS. For instance, [this collection](https://github.com/koldunovn/python_for_geosciences) focuses specifically on geosciences, and covers much of the same material we've discussed here. Hopefully, after this workshop, you now know how to download and open these kinds of collections from github!\n",
    "\n",
    "[This one](http://nbviewer.ipython.org/github/vins31/gis-experiments/blob/master/Altitude%20roads.ipynb) is a bit more advanced than what we've done, but shows *one* way to map using python. Another is [here](http://sensitivecities.com/so-youd-like-to-make-a-map-using-python-EN.html). \n",
    "\n",
    "I particularly like the styles in the second link, and it uses `shapely` and `pysal`, which we'll cover next week. Everything on that link is installed on the lab computers EXCEPT `fiona` and `descartes`, which I think are also very helpful packages. I'll talk about them, and I recommend you install them on your personal machines. However, with `pysal`, you don't need `fiona` to handle shapefiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ESRI is even getting into the game here...](https://github.com/Esri/gis-stat-analysis-py-tutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did some discussion on `pandas.merge` last night. The [doucumentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html), while very clear, may be too terse for you to understand at this point. So, let's talk clearly and openly about what the hell SQL-like joins are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Cardinalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have cardinalities. We've covered these before. If we have two datasets, A and B, the relationship between each element of A to each element of B is described by the \"cardinality\" of the join. \n",
    "\n",
    "If every element of A has a matching element in B, the join is **one to one**. \n",
    "\n",
    "If every element of A has *more than one* matching element in B, the join is **one to many**.\n",
    "\n",
    "If many elements of A match to only one element in B, the join is **many to one**. \n",
    "\n",
    "If many elements of A match to only one element in B, and many elements of B map to only one element of A, the join is **many to many**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins have \"directions\" or \"orientations\" that describe how the cardinality will be used to merge the datasets. For example, consider:\n",
    "\n",
    "        pandas.merge(A, B)\n",
    "\n",
    "In this example, `A` is the \"left\" dataframe and B is the \"right\" dataframe. Thus, *left* joins are joins that preserve elements of the *left* dataframe, and *right* joins preserve the *right* dataframe. \n",
    "\n",
    "Then, a join could be either \"inner\" or \"outer.\" *Inner* joins only keep the *intersection* of the keys. *Outer* joins keep the union of keys.\n",
    "\n",
    "For a good visualization, check out [this blog](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
